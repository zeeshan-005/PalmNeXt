# -*- coding: utf-8 -*-
"""02-resnet13-cnn-attention-on-date-leaves.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qjEMclH1R3vyyvjnNqNm4fyBCtfaAZdp
"""

import os
import cv2
import albumentations as A
import albumentations.pytorch
import torch
from torch.utils.data import Dataset, DataLoader
from torch import nn, optim
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Subset
import pickle
import torch.nn.functional as F
from sklearn.metrics import confusion_matrix, accuracy_score

# Define transforms for data augmentation and normalization
transform = transforms.Compose([
    transforms.Resize((128, 128)),  # Resize images to 224x224
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load the dataset
root_dir = '/kaggle/input/palm-leaves-dataset/Palm Leaves Dataset'  # Path to the dataset root folder
dataset = datasets.ImageFolder(root=root_dir, transform=transform)

# Split dataset indices into training (75%), validation (15%), and test (10%)
train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.10, stratify=dataset.targets)
train_idx, val_idx = train_test_split(train_idx, test_size=0.15/0.90, stratify=[dataset.targets[i] for i in train_idx])

# Create subsets
train_dataset = Subset(dataset, train_idx)
val_dataset = Subset(dataset, val_idx)
test_dataset = Subset(dataset, test_idx)

# Create dataloaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Example to check the number of samples in each split
print(f"Training samples: {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")
print(f"Test samples: {len(test_dataset)}")

import torchvision.models as models

# Load Pretrained ResNet (modifying ResNet-18 to act like ResNet-13)
class ResNet13(nn.Module):
    def __init__(self):
        super(ResNet13, self).__init__()
        # Load pre-trained ResNet-18
        resnet = models.resnet18(pretrained=True)

        # Modify to mimic ResNet-13 (we remove some layers here to simulate)
        self.resnet_feature_extractor = nn.Sequential(
            *list(resnet.children())[:-3]  # Keep up to layer 3 of ResNet-18
        )

    def forward(self, x):
        x = self.resnet_feature_extractor(x)
        return x

class SelfAttention(nn.Module):
    def __init__(self, in_channels):
        super(SelfAttention, self).__init__()
        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)
        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)
        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)
        self.softmax = nn.Softmax(dim=-1)
        self.gamma = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        batch_size, C, width, height = x.size()
        proj_query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)
        proj_key = self.key_conv(x).view(batch_size, -1, width * height)
        energy = torch.bmm(proj_query, proj_key)
        attention = self.softmax(energy)
        proj_value = self.value_conv(x).view(batch_size, -1, width * height)

        out = torch.bmm(proj_value, attention.permute(0, 2, 1))
        out = out.view(batch_size, C, width, height)

        out = self.gamma * out + x
        return out

class CNN_Attention(nn.Module):
    def __init__(self, num_classes=4):
        super(CNN_Attention, self).__init__()
        self.conv1 = nn.Conv2d(512, 128, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)
        self.attention = SelfAttention(32)
        # Adjusting the pooling size or removing it
        self.fc = nn.Linear(32 * 1 * 1, num_classes)  # Update this based on the actual final feature map size

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2)  # Ensure this doesn't shrink too much
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)  # Same here
        x = F.relu(self.conv3(x))
        x = self.attention(x)
        # You may want to avoid additional pooling if the feature map is already very small
        # x = F.max_pool2d(x, 2)  # Removing this might help
        x = x.view(x.size(0), -1)  # Flatten
        x = self.fc(x)
        return F.log_softmax(x, dim=1)

class ResNet13_CNN_Attention(nn.Module):
    def __init__(self, num_classes=4):
        super(ResNet13_CNN_Attention, self).__init__()
        self.resnet = torchvision.models.resnet18(pretrained=True)  # Using ResNet-13 equivalent
        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])  # Remove fully connected layer

        # CNN with Attention
        self.cnn_attention = CNN_Attention(num_classes)

    def forward(self, x):
        with torch.no_grad():
            x = self.resnet(x)
        x = self.cnn_attention(x)
        return x

#pip install torchvision

import torchvision
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ResNet13_CNN_Attention(num_classes=4).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training loop (similar to your previous loop, modified to use this model)
def train(model, train_loader, criterion, optimizer, device):
    model.train()
    train_loss = 0
    correct = 0
    for data, target in train_loader:
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
    train_loss /= len(train_loader.dataset)
    train_accuracy = 100. * correct / len(train_loader.dataset)
    return train_loss, train_accuracy

# Validation (and test)
def validate(model, val_loader, criterion, device):
    model.eval()
    val_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in val_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            val_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    val_loss /= len(val_loader.dataset)
    val_accuracy = 100. * correct / len(val_loader.dataset)
    return val_loss, val_accuracy

num_epochs = 50
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ResNet13_CNN_Attention(num_classes=4).to(device)

train_losses, val_losses = [], []
train_accuracies, val_accuracies = [], []

# Define optimizer and loss function
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training and validation loops
for epoch in range(num_epochs):
    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)
    val_loss, val_accuracy = validate(model, val_loader, criterion, device)

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accuracies.append(train_accuracy)
    val_accuracies.append(val_accuracy)

    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Train Acc: {train_accuracy}, Val Loss: {val_loss}, Val Acc: {val_accuracy}')

# Save the trained model and history
torch.save(model.state_dict(), 'ResNet13_CNN_Attention.pth')
history = {'train_losses': train_losses, 'val_losses': val_losses, 'train_accuracies': train_accuracies, 'val_accuracies': val_accuracies}
with open('ResNet13_CNN_Attention_training_history.pkl', 'wb') as f:
    pickle.dump(history, f)

# Load training history
with open('ResNet13_CNN_Attention_training_history.pkl', 'rb') as f:
    history = pickle.load(f)

# Plot training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(history['train_losses'], label='Train Loss')
plt.plot(history['val_losses'], label='Validation Loss')
plt.legend()
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.show()

# Plot training and validation accuracy
plt.figure(figsize=(10, 5))
plt.plot(history['train_accuracies'], label='Train Accuracy')
plt.plot(history['val_accuracies'], label='Validation Accuracy')
plt.legend()
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.show()

def test(model, test_loader, device):
    model.eval()
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for data, target in test_loader:
            # Move data and target to the GPU
            data, target = data.to(device), target.to(device)

            output = model(data)
            pred = output.argmax(dim=1, keepdim=True)
            all_preds.extend(pred.cpu().numpy())  # Move predictions to CPU for further processing
            all_targets.extend(target.cpu().numpy())  # Move targets to CPU for further processing

    return all_preds, all_targets

# Assuming val_loader is being used as the test_loader here
test_preds, test_targets = test(model, val_loader, device)

# Compute confusion matrix and accuracy
conf_matrix = confusion_matrix(test_targets, test_preds)
test_accuracy = accuracy_score(test_targets, test_preds)

print(f'Test Accuracy: {test_accuracy * 100:.2f}%')
plt.figure(figsize=(8, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=dataset.classes, yticklabels=dataset.classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(test_targets, test_preds))

!zip -r file.zip /kaggle/working

from IPython.display import FileLink
FileLink(r'file.zip')

